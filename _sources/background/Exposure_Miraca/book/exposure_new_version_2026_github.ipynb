{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc488a3-233e-4e23-bece-be5ed1427551",
   "metadata": {},
   "source": [
    "# Exposure database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37238ef6-54f1-4d89-a678-e71d496e266b",
   "metadata": {},
   "source": [
    "This notebook provides a systematic approach for analyzing and visualizing infrastructure networks across different European countries. It iterates through a list of countries and network types, retrieves the relevant geographic data, processes it to handle missing values, and generates visualizations to provide insights into the infrastructure distribution and characteristics within each country. Raw geospatial data is sourced from multiple databases, including OSM. Integration with OSM data is achieved using the OSMnx Python library, which simplifies downloading, modeling, analyzing, and visualizing OSM data. The integrated data is associated with EU codes representing all European countries (e.g., FR for France, NL for Netherlands). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7946a43-d70a-4326-8c74-be5ce8535bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "# Import necessary libraries\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import re\n",
    "import shapely\n",
    "from shapely.geometry import (\n",
    "    MultiPolygon,\n",
    "    GeometryCollection,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools,operator\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ceaa2c-c973-4897-b146-4c25368e1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder where the database will be stored\n",
    "# TODO: We could set a .miraca folder as a default for all packages\n",
    "Miraca_Exposure_Database_path = Path(\"~/miraca_exposure_database\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f6aba6-4460-4dec-9c24-91855531cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder where the Geofabrik data is available\n",
    "data_path = r\"C:\\Users\\Paraskevi Tsoumani\\OneDrive - Vrije Universiteit Amsterdam\\Documenten - MIRACA\\General\\Deliverables and Milestones\\Milestone_Intermediate version of harmonised exposure database\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4f84ce-d688-4b88-88c8-50bdb91eca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENT_roads_path = data_path / \"europe_road_edges_TENT.parquet\"\n",
    "TENT_rail_path = data_path / \"europe_railways_edges_TENT.parquet\"\n",
    "LAU_path  = data_path / \"LAU_RG_01M_2024_3035.geojson\"\n",
    "NUTS_path = data_path / \"NUTS_RG_01M_2024_3035.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ac2df3-640a-479e-8014-cdb1a99c5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_CIS_OSM = {\n",
    "    \"Roads\": {\n",
    "        \"osm_keys\": [\"highway\", \"name\", \"maxspeed\", \"lanes\", \"surface\",\"bridge\",\"ref\"],\n",
    "        \"osm_query\": {\n",
    "            \"highway\": [\n",
    "                \"motorway\",\n",
    "                \"motorway_link\",\n",
    "                \"trunk\",\n",
    "                \"trunk_link\",\n",
    "                \"primary\",\n",
    "                \"primary_link\",\n",
    "                \"secondary\",\n",
    "                \"secondary_link\",\n",
    "                \"tertiary\",\n",
    "                \"tertiary_link\",\n",
    "                \"residential\",\n",
    "                \"road\",\n",
    "                \"unclassified\",\n",
    "                \"track\",\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    \"Roadway\": {\n",
    "        \"osm_keys\": [\"highway\", \"name\", \"maxspeed\", \"lanes\", \"surface\"],\n",
    "        \"osm_query\": {\n",
    "            \"highway\": [\n",
    "                \"primary\",\n",
    "                \"primary_link\",\n",
    "                \"secondary\",\n",
    "                \"secondary_link\",\n",
    "                \"tertiary\",\n",
    "                \"tertiary_link\",\n",
    "                \"trunk\",\n",
    "                \"trunk_link\",\n",
    "                \"motorway\",\n",
    "                \"motorway_link\",\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    \"Railway\": {\n",
    "        \"osm_keys\": [\"railway\", \"name\", \"gauge\", \"electrified\", \"voltage\"],\n",
    "        \"osm_query\": {\"railway\": [\"rail\", \"narrow_gauge\"]},\n",
    "    },\n",
    "    \"Airports\": {\n",
    "        \"osm_keys\": [\"aeroway\", \"name\", \"\"],\n",
    "        \"osm_query\": {\"aeroway\": [\"aerodrome\", \"apron\", \"terminal\", \"runway\"]},\n",
    "    },\n",
    "    \"Telecommunication\": {\n",
    "        \"osm_keys\": [\"man_made\", \"tower:type\", \"name\"],\n",
    "        \"osm_query\": {\n",
    "            \"man_made\": [\"mast\", \"communications_tower\"],\n",
    "            \"tower:type\": [\"communication\"],\n",
    "        },\n",
    "    },\n",
    "    \"Water_supply\": {\n",
    "        \"osm_keys\": [\"man_made\", \"name\"],\n",
    "        \"osm_query\": {\n",
    "            \"man_made\": [\n",
    "                \"water_works\",\n",
    "                \"water_well\",\n",
    "                \"water_tower\",\n",
    "                \"reservoir_covered\",\n",
    "                \"storage_tank\",\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    \"Waste_solid\": {\n",
    "        \"osm_keys\": [\"amenity\", \"name\"],\n",
    "        \"osm_query\": {\"amenity\": [\"waste_transfer_station\"]},\n",
    "    },\n",
    "    \"Waste_water\": {\n",
    "        \"osm_keys\": [\"man_made\", \"name\"],\n",
    "        \"osm_query\": {\"man_made\": [\"wastewater_plant\"]},\n",
    "    },\n",
    "    \"Education\": {\n",
    "        \"osm_keys\": [\"amenity\", \"building\", \"name\"],\n",
    "        \"osm_query\": {\n",
    "            \"building\": [\"school\", \"kindergarten\", \"college\", \"university\", \"library\"],\n",
    "            \"amenity\": [\"school\", \"kindergarten\", \"college\", \"university\", \"library\"],\n",
    "        },\n",
    "    },\n",
    "    \"Healthcare\": {\n",
    "        \"osm_keys\": [\"amenity\", \"building\", \"healthcare\", \"name\"],\n",
    "        \"osm_query\": {\n",
    "            \"amenity\": [\"hospital\", \"clinic\", \"doctors\", \"dentist\", \"pharmacy\"],\n",
    "            \"building\": [\"hospital\", \"clinic\"],\n",
    "            \"healthcare\": [\n",
    "                \"pharmacy\",\n",
    "                \"dentist\",\n",
    "                \"physiotherapist\",\n",
    "                \"alternative\",\n",
    "                \"laboratory\",\n",
    "                \"optometrist\",\n",
    "                \"rehabilitation\",\n",
    "                \"blood_donation\",\n",
    "                \"birthing_center\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    \"Power\": {\n",
    "        \"osm_keys\": [\"power\", \"voltage\", \"utility\", \"name\", \"source\"],\n",
    "        \"osm_query\": {\n",
    "            \"power\": [\n",
    "                \"line\",\n",
    "                \"cable\",\n",
    "                \"minor_line\",\n",
    "                \"plant\",\n",
    "                \"generator\",\n",
    "                \"substation\",\n",
    "                \"transformer\",\n",
    "                \"pole\",\n",
    "                \"portal\",\n",
    "                \"tower\",\n",
    "                \"terminal\",\n",
    "                \"switch\",\n",
    "                \"catenary_mast\",\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    \"Gas\": {\n",
    "        \"osm_keys\": [\"man_made\", \"pipeline\", \"utility\", \"name\", \"substance\", \"content\"],\n",
    "        \"osm_query\": {\n",
    "            \"man_made\": [\"pipeline\", \"storage_tank\"],\n",
    "            \"pipeline\": [\"substation\"],\n",
    "            \"utility\": [\"gas\"],\n",
    "            \"substance\": [\"gas\"],\n",
    "            \"content\": [\"gas\"],\n",
    "        },\n",
    "    },\n",
    "    \"Food\": {\n",
    "        \"osm_keys\": [\"amenity\", \"building\", \"name\"],\n",
    "        \"osm_query\": {\n",
    "            \"amenity\": [\"restaurant\", \"fast_food\", \"cafe\", \"pub\", \"bar\"],\n",
    "            \"building\": [\"restaurant\", \"fast_food\", \"cafe\", \"pub\", \"bar\"],\n",
    "        },\n",
    "    },\n",
    "    \"Oil\": {\n",
    "        \"osm_keys\": [\"pipeline\", \"man_made\", \"amenity\", \"name\", \"substance\"],\n",
    "        \"osm_query\": {\n",
    "            \"pipeline\": [\"substation\"],\n",
    "            \"man_made\": [\"pipeline\", \"petroleum_well\", \"oil_refinery\"],\n",
    "            \"amenity\": [\"fuel\"],\n",
    "            \"substance\": [\"oil\"],\n",
    "        },\n",
    "    },\n",
    "    \"Buildings\": {\n",
    "        \"osm_keys\": [\"building\", \"amenity\", \"name\"],\n",
    "        \"osm_query\": {\n",
    "            \"building\": [\n",
    "                \"yes\",\n",
    "                \"house\",\n",
    "                \"residential\",\n",
    "                \"detached\",\n",
    "                \"hut\",\n",
    "                \"industrial\",\n",
    "                \"shed\",\n",
    "                \"apartments\",\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "OBJECTS_TO_KEEP = {\n",
    "    \"Roads\": [\"motorway\", \"motorway_link\", \"trunk\", \"trunk_link\", \"primary\", \"primary_link\", \"secondary\", \"secondary_link\", \"tertiary\", \"tertiary_link\", \"residential\", \"road\", \"unclassified\", \"track\"],\n",
    "    \"Roadway\": [\"primary\", \"primary_link\", \"secondary\", \"secondary_link\", \"tertiary\", \"tertiary_link\", \"trunk\", \"trunk_link\", \"motorway\", \"motorway_link\"],\n",
    "    \"Railway\": [\"rail\", \"narrow_gauge\"],\n",
    "    \"Airports\": [\"aerodrome\", \"apron\", \"terminal\", \"runway\"],\n",
    "    \"Telecommunication\": [\"mast\", \"communications_tower\", \"communication\"],\n",
    "    \"Water_supply\": [\"water_works\", \"water_well\", \"water_tower\", \"reservoir_covered\", \"storage_tank\"],\n",
    "    \"Waste_solid\": [\"waste_transfer_station\"],\n",
    "    \"Waste_water\": [\"wastewater_plant\"],\n",
    "    \"Education\": [\"school\", \"kindergarten\", \"college\", \"university\", \"library\"],\n",
    "    \"Healthcare\": [\"hospital\", \"clinic\", \"doctors\", \"dentist\", \"pharmacy\", \"physiotherapist\", \"alternative\", \"laboratory\", \"optometrist\", \"rehabilitation\", \"blood_donation\", \"birthing_center\"],\n",
    "    \"Power\": [\"line\", \"cable\", \"minor_line\", \"plant\", \"generator\", \"substation\", \"transformer\", \"pole\", \"portal\", \"tower\", \"terminal\", \"switch\", \"catenary_mast\"],\n",
    "    \"Gas\": [\"pipeline\", \"storage_tank\", \"substation\", \"gas\"],\n",
    "    \"Food\": [\"restaurant\", \"fast_food\", \"cafe\", \"pub\", \"bar\"],\n",
    "    \"Oil\": [\"substation\", \"pipeline\", \"petroleum_well\", \"oil_refinery\", \"fuel\", \"oil\"],\n",
    "    \"Buildings\": [\"yes\", \"house\", \"residential\", \"detached\", \"hut\", \"industrial\", \"shed\", \"apartments\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f3af10-df25-4604-88c0-8b5fb47498e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_contained_assets(features):\n",
    "    \"\"\"\n",
    "    Remove assets whose geometries are fully contained within others.\n",
    "\n",
    "    Args:\n",
    "        features (gpd.GeoDataFrame): GeoDataFrame with point and polygon features.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Cleaned GeoDataFrame with unique geometries.\n",
    "    \"\"\"\n",
    "    features = _remove_contained_polys(\n",
    "        _remove_contained_points(features)\n",
    "    )  # remove points and polygons within a (larger) polygon\n",
    "\n",
    "    return features\n",
    "def _remove_contained_points(gdf_p_mp):\n",
    "    \"\"\"\n",
    "    Remove point features contained within any polygon in the dataset.\n",
    "\n",
    "    Args:\n",
    "        gdf_p_mp (gpd.GeoDataFrame): GeoDataFrame with point and polygon geometries.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: GeoDataFrame without contained points.\n",
    "    \"\"\"\n",
    "    gdf_p_mp = gdf_p_mp.reset_index(drop=True)\n",
    "\n",
    "    ind_dupl = np.unique(\n",
    "        gpd.sjoin(\n",
    "            gdf_p_mp[gdf_p_mp.geometry.type == \"Point\"],\n",
    "            gdf_p_mp[\n",
    "                (gdf_p_mp.geometry.type == \"MultiPolygon\")\n",
    "                | (gdf_p_mp.geometry.type == \"Polygon\")\n",
    "            ],\n",
    "            predicate=\"within\",\n",
    "        ).index\n",
    "    )\n",
    "\n",
    "    return gdf_p_mp.drop(index=ind_dupl).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _remove_contained_polys(gdf):\n",
    "    \"\"\"\n",
    "    From a GeoDataFrame containing (multi-)polygons (and potentially other\n",
    "    geometries), remove those polygon entries that are already fully\n",
    "    contained in another polygon entries. Removes smaller polygons within\n",
    "    polygons and full duplicates, but leaves contained points untouched\n",
    "    (see remove_contained_points() for this).\n",
    "\n",
    "    Resets the index of the dataframe.\n",
    "\n",
    "    Args:\n",
    "        gdf (gpd.GeoDataFrame): GeoDataFrame with polygon geometries.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: GeoDataFrame with outermost geometries.\n",
    "    \"\"\"\n",
    "\n",
    "    gdf = gdf.reset_index(drop=True)\n",
    "\n",
    "    contained = gpd.sjoin(\n",
    "        gdf[(gdf.geometry.type == \"MultiPolygon\") | (gdf.geometry.type == \"Polygon\")],\n",
    "        gdf[(gdf.geometry.type == \"MultiPolygon\") | (gdf.geometry.type == \"Polygon\")],\n",
    "        predicate=\"contains\",\n",
    "    )\n",
    "\n",
    "    subset = contained[contained.index != contained.index_right]\n",
    "    to_drop = set(subset.index_right) - set(subset.index)\n",
    "\n",
    "    return gdf.drop(index=to_drop).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def extract_first_geom(geom):\n",
    "    \"\"\"\n",
    "    Extract the first geometry from a GeometryCollection.\n",
    "\n",
    "    Args:\n",
    "        geom (shapely.Geometry): Shapely geometry object.\n",
    "\n",
    "    Returns:\n",
    "        shapely.Geometry: First geometry or unchanged object.\n",
    "    \"\"\"\n",
    "    if isinstance(geom, GeometryCollection) and len(geom.geoms) > 0:\n",
    "        return geom.geoms[0]\n",
    "\n",
    "    return geom\n",
    "\n",
    "def _extract_value(text, key):\n",
    "    \"\"\"\n",
    "    Parse the value of a specific key from a semi-structured OSM tag string.\n",
    "\n",
    "    Args:\n",
    "        text (str): Raw OSM `other_tags` string.\n",
    "        key (str): Key to extract value for.\n",
    "\n",
    "    Returns:\n",
    "        str or None: Extracted value or None.\n",
    "    \"\"\"\n",
    "    pattern = rf'\"{key}\"=>\"([^\"]+)\"'\n",
    "    try:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract(osm_path, geom_type, osm_keys, osm_query):\n",
    "    \"\"\"\n",
    "    Extract specific infrastructure features from a .pbf file using OSM keys/values.\n",
    "\n",
    "    Args:\n",
    "        osm_path (str or Path): Path to .osm.pbf file.\n",
    "        geom_type (str): One of 'points', 'lines', 'multipolygons'.\n",
    "        osm_keys (list): Keys to extract from OSM file.\n",
    "        osm_query (dict): Key-value mapping used to filter.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Extracted GeoDataFrame with `object_type` field.\n",
    "    \"\"\"\n",
    "    features = gpd.read_file(osm_path, layer=geom_type, engine=\"pyogrio\")\n",
    "\n",
    "    if \"osm_way_id\" in features.columns:\n",
    "        features[\"osm_id\"] = features[\"osm_id\"].fillna(features[\"osm_way_id\"])\n",
    "\n",
    "    for key in osm_keys:\n",
    "        if key not in features.columns:\n",
    "            features[key] = features[\"other_tags\"].apply(\n",
    "                lambda x: _extract_value(x, key)\n",
    "            )\n",
    "\n",
    "    # build query\n",
    "    collect_indices = []\n",
    "    for query_key in osm_query.keys():\n",
    "        collect_indices.append(\n",
    "            features[features[query_key].isin(osm_query[query_key])].index.values\n",
    "        )\n",
    "\n",
    "    # get complete list\n",
    "    collect_indices = functools.reduce(operator.iconcat, collect_indices, [])\n",
    "\n",
    "    # remove duplicates from list\n",
    "    collect_indices = list(set(collect_indices))\n",
    "    features = features.iloc[collect_indices]\n",
    "\n",
    "    features = features[[\"osm_id\", \"geometry\"] + osm_keys]\n",
    "\n",
    "    features.rename(columns={osm_keys[0]: \"object_type\"}, inplace=True)\n",
    "\n",
    "    return features\n",
    "\n",
    "def read_osm_data(osm_path, asset_type):\n",
    "    \"\"\"\n",
    "    Load and extract OSM features for a given critical infrastructure type.\n",
    "\n",
    "    Args:\n",
    "        osm_path (str or Path): Path to .osm.pbf file.\n",
    "        asset_type (str): One of the keys in DICT_CIS_OSM.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Cleaned and validated exposure GeoDataFrame.\n",
    "\n",
    "    Raises:\n",
    "        ImportWarning: If asset_type is not supported.\n",
    "    \"\"\"\n",
    "    # features consisting in points and multipolygon results:\n",
    "    if asset_type in [\"Healthcare\", \"Education\", \"Food\", \"Buildings\"]:\n",
    "        gdf = pd.concat(\n",
    "            [\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"points\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"multipolygons\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # features consisting in points, multipolygons and lines:\n",
    "    elif asset_type in [\"Gas\", \"Oil\", \"Water\", \"Power\"]:\n",
    "        gdf = pd.concat(\n",
    "            [\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"points\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"multipolygons\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"lines\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # features consisting in multipolygons and lines:\n",
    "    elif asset_type in [\"Airports\"]:\n",
    "        gdf = pd.concat(\n",
    "            [\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"multipolygons\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"lines\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # features consisting in multiple datattypes, but only lines needed:\n",
    "    elif asset_type in [\"Railway\", \"Roads\", \"Roadway\"]:\n",
    "        gdf = pd.concat(\n",
    "            [\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"lines\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # features consisting in all data types, but only points and multipolygon needed:\n",
    "    elif asset_type in [\n",
    "        \"Telecommunication\",\n",
    "        \"wastewater\",\n",
    "        \"waste_solid\",\n",
    "        \"waste_water\",\n",
    "        \"water_supply\",\n",
    "    ]:\n",
    "        gdf = pd.concat(\n",
    "            [\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"points\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "                extract(\n",
    "                    osm_path,\n",
    "                    \"multipolygons\",\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_keys\"],\n",
    "                    DICT_CIS_OSM[asset_type][\"osm_query\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ImportWarning(\"feature not in DICT_CIS_OSM. Returning empty gdf\")\n",
    "\n",
    "    # make all geometries valid\n",
    "    gdf[\"geometry\"] = shapely.make_valid(gdf[\"geometry\"])\n",
    "    gdf = gdf[gdf.geometry.is_valid]\n",
    "\n",
    "    # only keep assets with unique geometries\n",
    "    features = _remove_contained_assets(gdf)\n",
    "\n",
    "    # remove potential geometrycollections to avoid errors later on\n",
    "    features[\"geometry\"] = features[\"geometry\"].apply(extract_first_geom)\n",
    "\n",
    "    # remove features that are not in the asset_type list\n",
    "    unique_objects_in_asset_type = OBJECTS_TO_KEEP[asset_type]\n",
    "\n",
    "    return features[features[\"object_type\"].isin(unique_objects_in_asset_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4298a91d-5336-4bc0-bc60-f291e0ef61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mixed_geometries_to_polygons(features, asset_type):\n",
    "    \"\"\"\n",
    "    Convert point and linestring geometries to polygons for asset types with mixed geometry types.\n",
    "    Only converts geometries for object types that have at least some polygon representations.\n",
    "    Respects specific object types that should maintain their original geometry.\n",
    "    \n",
    "    Args:\n",
    "        features (gpd.GeoDataFrame): Infrastructure features\n",
    "        asset_type (str): Type of infrastructure asset\n",
    "        \n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: Features with consistent polygon geometries where appropriate\n",
    "    \"\"\"\n",
    "    # Only apply for certain asset types\n",
    "    if asset_type not in ['Education', 'Healthcare', 'Telecommunication','Power','Gas', 'Oil']:\n",
    "        return features\n",
    "    \n",
    "    # Define object types that should NOT be converted for each asset type\n",
    "    preserve_geometry = {\n",
    "        'Power': {\n",
    "            'line': 'LineString',      # Should always remain as lines\n",
    "            'tower': 'Point',          # Should always remain as points\n",
    "            'pole': 'Point',           # Should always remain as points\n",
    "            'catenary_mast': 'Point',  # Should always remain as points\n",
    "            'cable': 'LineString',     # Should always remain as lines\n",
    "            'minor_line': 'LineString' # Should always remain as lines\n",
    "        },\n",
    "        'Gas': {\n",
    "            'pipeline': 'LineString'   # Should always remain as lines\n",
    "        },\n",
    "        'Oil': {\n",
    "            'pipeline': 'LineString'   # Should always remain as lines\n",
    "        },\n",
    "        'Telecommunication': {    \n",
    "            'mast': 'Point',           # Should always remain as points\n",
    "            'communications_tower': 'Point'  # Should always remain as points\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # Get the preserve list for this asset type\n",
    "    preserve_list = preserve_geometry.get(asset_type, {})\n",
    "    \n",
    "    # Add geometry type information\n",
    "    features['geom_type'] = features.geometry.geom_type\n",
    "    \n",
    "    # Create a mask for features that should preserve their geometry\n",
    "    preserve_mask = pd.Series(False, index=features.index)\n",
    "    for obj_type, geom_type in preserve_list.items():\n",
    "        # Mark features with this object_type to preserve if they have the right geometry\n",
    "        type_mask = (features['object_type'] == obj_type) & (features['geom_type'] == geom_type)\n",
    "        preserve_mask = preserve_mask | type_mask\n",
    "    \n",
    "    # Get polygon features to calculate median areas (only for non-preserved features)\n",
    "    polygon_features = features.loc[\n",
    "        (~preserve_mask) & features.geom_type.isin(['Polygon', 'MultiPolygon'])\n",
    "    ].to_crs(3035)\n",
    "    \n",
    "    # If no polygon features exist, return original features\n",
    "    if len(polygon_features) == 0:\n",
    "        features = features.drop(['geom_type'], axis=1)\n",
    "        return features\n",
    "        \n",
    "    polygon_features['square_m2'] = polygon_features.area\n",
    "    \n",
    "    # Calculate median area by object type\n",
    "    square_m2_object_type = polygon_features[['object_type', 'square_m2']].groupby('object_type').median()\n",
    "    \n",
    "    # Default area if median cannot be calculated (1000 sq meters ~ small building)\n",
    "    default_area = 1000\n",
    "    \n",
    "    # Find object types that have mixed geometries (linestrings + polygons)\n",
    "    # Only consider non-preserved features\n",
    "    non_preserved_features = features[~preserve_mask]\n",
    "    mixed_geom_types = non_preserved_features.groupby(['object_type', 'geom_type']).size().unstack().fillna(0)\n",
    "    \n",
    "    # Identify object types that have both linestrings and polygons\n",
    "    linestrings_to_polygonize = []\n",
    "    if 'LineString' in mixed_geom_types.columns and any(col in mixed_geom_types.columns for col in ['Polygon', 'MultiPolygon']):\n",
    "        for obj_type in mixed_geom_types.index:\n",
    "            # Skip if this object type should be preserved\n",
    "            if obj_type in preserve_list and preserve_list[obj_type] == 'LineString':\n",
    "                continue\n",
    "                \n",
    "            line_count = mixed_geom_types.loc[obj_type, 'LineString'] if 'LineString' in mixed_geom_types.columns else 0\n",
    "            poly_count = sum(mixed_geom_types.loc[obj_type, col] for col in ['Polygon', 'MultiPolygon'] \n",
    "                            if col in mixed_geom_types.columns)\n",
    "            \n",
    "            # If this object type has both linestrings and polygons, add to conversion list\n",
    "            if line_count > 0 and poly_count > 0:\n",
    "                linestrings_to_polygonize.append(obj_type)\n",
    "    \n",
    "    # Convert linestrings to polygons\n",
    "    if linestrings_to_polygonize:\n",
    "        print(f\"Converting linestrings to polygons for {asset_type}: {linestrings_to_polygonize}\")\n",
    "        \n",
    "        # Get linestrings to convert\n",
    "        all_linestrings_to_polygonize = features.loc[\n",
    "            (features.object_type.isin(linestrings_to_polygonize)) & \n",
    "            (features.geom_type == 'LineString') &\n",
    "            (~preserve_mask)  # Ensure we don't convert preserved features\n",
    "        ]\n",
    "        \n",
    "        if len(all_linestrings_to_polygonize) > 0:\n",
    "            # Define function to convert linestring to polygon\n",
    "            def polygonize_linestring(linestring):\n",
    "                try:\n",
    "                    # Simple conversion for closed linestrings\n",
    "                    if linestring.is_closed:\n",
    "                        return shapely.geometry.Polygon(linestring)\n",
    "                    else:\n",
    "                        # For open linestrings, create a small buffer\n",
    "                        return linestring.buffer(0.0001)\n",
    "                except Exception:\n",
    "                    # Fallback: create a small buffer\n",
    "                    return linestring.buffer(0.0001)\n",
    "            \n",
    "            # Apply conversion\n",
    "            new_geometries = all_linestrings_to_polygonize.geometry.apply(polygonize_linestring).values\n",
    "            \n",
    "            # Update geometries\n",
    "            features.loc[\n",
    "                (features.object_type.isin(linestrings_to_polygonize)) & \n",
    "                (features.geom_type == 'LineString') &\n",
    "                (~preserve_mask),  # Ensure we don't convert preserved features\n",
    "                'geometry'\n",
    "            ] = new_geometries\n",
    "    \n",
    "    # Get the points to convert (only for object types that also have polygons)\n",
    "    points_to_polygonize = []\n",
    "    if 'Point' in mixed_geom_types.columns and any(col in mixed_geom_types.columns for col in ['Polygon', 'MultiPolygon']):\n",
    "        for obj_type in mixed_geom_types.index:\n",
    "            # Skip if this object type should be preserved\n",
    "            if obj_type in preserve_list and preserve_list[obj_type] == 'Point':\n",
    "                continue\n",
    "                \n",
    "            point_count = mixed_geom_types.loc[obj_type, 'Point'] if 'Point' in mixed_geom_types.columns else 0\n",
    "            poly_count = sum(mixed_geom_types.loc[obj_type, col] for col in ['Polygon', 'MultiPolygon'] \n",
    "                            if col in mixed_geom_types.columns)\n",
    "            \n",
    "            # If this object type has both points and polygons, add to conversion list\n",
    "            if point_count > 0 and poly_count > 0:\n",
    "                points_to_polygonize.append(obj_type)\n",
    "    \n",
    "    if points_to_polygonize:\n",
    "        all_assets_to_polygonize = features.loc[\n",
    "            (features.object_type.isin(points_to_polygonize)) & \n",
    "            (features.geom_type == 'Point') &\n",
    "            (~preserve_mask)  # Ensure we don't convert preserved features\n",
    "        ].to_crs(3035)\n",
    "        \n",
    "        if len(all_assets_to_polygonize) > 0:\n",
    "            print(f\"Converting {len(all_assets_to_polygonize)} points to polygons for {asset_type}: {points_to_polygonize}\")\n",
    "            \n",
    "            # Define function to polygonize points\n",
    "            def polygonize_point_per_asset(asset):\n",
    "                # Get buffer length (half of width/length)\n",
    "                if asset.object_type in square_m2_object_type.index:\n",
    "                    area = square_m2_object_type.loc[asset.object_type].values[0]\n",
    "                else:\n",
    "                    area = default_area\n",
    "                    \n",
    "                buffer_length = np.sqrt(area) / 2\n",
    "                \n",
    "                # Buffer the point to create a square polygon\n",
    "                return asset.geometry.buffer(buffer_length, cap_style='square')\n",
    "            \n",
    "            # Apply the conversion\n",
    "            new_geometries = all_assets_to_polygonize.apply(\n",
    "                lambda asset: polygonize_point_per_asset(asset), axis=1\n",
    "            ).set_crs(3035).to_crs(3035).values\n",
    "            \n",
    "            # Update the geometries\n",
    "            features.loc[\n",
    "                (features.object_type.isin(points_to_polygonize)) & \n",
    "                (features.geom_type == 'Point') &\n",
    "                (~preserve_mask),  # Ensure we don't convert preserved features\n",
    "                'geometry'\n",
    "            ] = new_geometries\n",
    "    \n",
    "    # Remove the temporary geom_type column\n",
    "    features = features.drop(['geom_type'], axis=1)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9179e9-54a4-4c17-ab24-fd2c8967314f",
   "metadata": {},
   "source": [
    "This dictionary maps the names of European countries to their respective ISO 3166-1 alpha-2 codes. These codes are two-letter country codes defined in the ISO 3166-1 standard.The dictionary keys are country names (str) and values are their ISO 3166-1 alpha-2 codes (str).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352b69e9-933f-485c-a078-08cda451c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "EU_code_full = {\n",
    "    \"AL\": \"Albania\",\n",
    "    \"AT\": \"Austria\",\n",
    "    \"BE\": \"Belgium\",\n",
    "    \"BG\": \"Bulgaria\",\n",
    "    \"CH\": \"Switzerland\",\n",
    "    \"CY\": \"Cyprus\",\n",
    "    \"CZ\": \"Czechia\",\n",
    "    \"DE\": \"Germany\",\n",
    "    \"DK\": \"Denmark\",\n",
    "    \"EE\": \"Estonia\",\n",
    "    \"EL\": \"Greece\",\n",
    "    \"ES\": \"Spain\",\n",
    "    \"FI\": \"Finland\",\n",
    "    \"FR\": \"France\",\n",
    "    \"HR\": \"Croatia\",\n",
    "    \"HU\": \"Hungary\",\n",
    "    \"IE\": \"Ireland\",\n",
    "    \"IS\": \"Iceland\",\n",
    "    \"IT\": \"Italy\",\n",
    "    \"LT\": \"Lithuania\",\n",
    "    \"LU\": \"Luxembourg\",\n",
    "    \"LV\": \"Latvia\",\n",
    "    \"MK\": \"North Macedonia\",\n",
    "    \"MT\": \"Malta\",\n",
    "    \"NL\": \"Netherlands\",\n",
    "    \"NO\": \"Norway\",\n",
    "    \"PL\": \"Poland\",\n",
    "    \"PT\": \"Portugal\",\n",
    "    \"RO\": \"Romania\",\n",
    "    \"SE\": \"Sweden\",\n",
    "    \"SI\": \"Slovenia\",\n",
    "    \"SK\": \"Slovakia\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301d8f8b-dbc4-4c5b-be88-1f47d4a66f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of networks\n",
    "network_list = [\n",
    "    \"Education\",\n",
    "    \"Healthcare\",\n",
    "    \"Airports\",\n",
    "    \"Ports\",\n",
    "    \"Roadway\",\n",
    "    \"Railway\",\n",
    "    \"Telecommunication\",\n",
    "    \"Power\",\n",
    "    \"Gas\",\n",
    "    \"Oil\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9553c798-7cdd-449e-ae04-5ae7407fb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose country \n",
    "country = 'PT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28af299e-ddd0-4c17-8fe4-8d37fe4ce8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose asset_type \n",
    "asset_type = 'Education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d13a2427-0eea-4443-8e82-242459f50217",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbf_file = \"portugal-260119.osm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca5da56e-1879-436c-a7c7-72c0830930a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paraskevi Tsoumani\\anaconda3\\envs\\miraca\\Lib\\site-packages\\pyogrio\\raw.py:200: RuntimeWarning: Non closed ring detected. To avoid accepting it, set the OGR_GEOMETRY_ACCEPT_UNCLOSED_RING configuration option to NO\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 41s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "osm_path = data_path / f\"{pbf_file}.pbf\"\n",
    "features = read_osm_data(osm_path,asset_type=asset_type)\n",
    "features_index = features.sindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19579e13-45ec-4b27-ac32-2eaa5e8c5c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LAU = gpd.read_file(LAU_path, engine=\"pyogrio\")\n",
    "NUTS = gpd.read_file(NUTS_path, engine=\"pyogrio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd409f0d-8b9d-4848-93b1-d15c88f11c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS2 = NUTS.loc[NUTS.LEVL_CODE == 2].reset_index(drop=True)\n",
    "NUTS_index = NUTS2.sindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57bae115-d4b4-4371-b738-bd0a2532af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NUTS2(LAU_region,NUTS2):\n",
    "\n",
    "    NUTS2_rough = NUTS2.iloc[NUTS_index.intersection((LAU_region.geometry.centroid.x,LAU_region.geometry.centroid.y))]\n",
    "    boolean = NUTS2_rough.intersects(LAU_region.geometry.centroid).values \n",
    "    try:\n",
    "        return NUTS2_rough.loc[boolean].NUTS_ID.values[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34d24876-a343-4ba4-bb83-fb7e788f23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAU_country = LAU.loc[LAU.CNTR_CODE == country] ## make sure this iso2 code is changed with different countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8706f28f-4aa4-479f-b690-ed65efc56d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3092/3092 [00:00<00:00, 3904.39it/s]\n",
      "C:\\Users\\Paraskevi Tsoumani\\anaconda3\\envs\\miraca\\Lib\\site-packages\\geopandas\\geodataframe.py:1528: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "LAU_country.loc[:,'NUTS2'] = LAU_country.progress_apply(lambda LAU_region: \n",
    "                                              get_NUTS2(LAU_region,NUTS2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eacc7e57-9a73-45d4-af55-cef04f627fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3092/3092 [00:01<00:00, 1663.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 1412 points to polygons for Education: ['college', 'kindergarten', 'library', 'school', 'university']\n"
     ]
    }
   ],
   "source": [
    "collect_assets = []\n",
    "for LAU_region in tqdm(LAU_country.to_crs(4326).itertuples(), total=len(LAU_country)):\n",
    "    # Get rough intersection using spatial index\n",
    "    assets_rough = features.iloc[features_index.intersection(LAU_region.geometry.bounds)].copy()\n",
    "    \n",
    "    # Skip if no assets found in bounding box\n",
    "    if assets_rough.empty:\n",
    "        continue\n",
    "\n",
    "    # Calculate precise intersection - assign to geometry column correctly\n",
    "    assets_rough['geometry'] = assets_rough.geometry.intersection(LAU_region.geometry)\n",
    "    \n",
    "    # Filter out empty geometries and make a copy to avoid warnings\n",
    "    assets_precise = assets_rough[~assets_rough.geometry.is_empty].copy()\n",
    "    \n",
    "    # Now safely assign new columns\n",
    "    assets_precise['LAU'] = LAU_region.GISCO_ID\n",
    "    assets_precise['NUTS2'] = LAU_region.NUTS2\n",
    "    assets_precise['CNTR_CODE'] = LAU_region.CNTR_CODE\n",
    "    collect_assets.append(assets_precise)\n",
    "  \n",
    "country_assets = pd.concat(collect_assets).to_crs(3035)\n",
    "country_assets.osm_id = country_assets.osm_id.astype(np.float64)\n",
    "country_assets = country_assets.loc[country_assets.is_valid]\n",
    "country_assets = country_assets.reset_index(drop=True)\n",
    "country_assets = convert_mixed_geometries_to_polygons(country_assets, asset_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76109c54-a2df-4f59-a4f1-3ae4131993e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for roads/railway: add corridor values\n",
    "if asset_type.lower() in [\"roadway\", \"railway\"]:\n",
    "\n",
    "    tent_path = TENT_roads_path if asset_type.lower() == \"roadway\" else TENT_rail_path\n",
    "\n",
    "    add_path = pd.read_parquet(tent_path)[[\"osm_way_id\", \"CORRIDORS\"]]\n",
    "    corridor_dict = dict(zip(add_path[\"osm_way_id\"], add_path[\"CORRIDORS\"]))\n",
    "\n",
    "    country_assets[\"CORRIDOR\"] = country_assets[\"osm_id\"].map(corridor_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2c01836-a4dc-4a8c-a342-fac0a703529d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osm_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>object_type</th>\n",
       "      <th>building</th>\n",
       "      <th>name</th>\n",
       "      <th>LAU</th>\n",
       "      <th>NUTS2</th>\n",
       "      <th>CNTR_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.851998e+08</td>\n",
       "      <td>POLYGON ((2772783.864 2240602.702, 2772815.477...</td>\n",
       "      <td>school</td>\n",
       "      <td>None</td>\n",
       "      <td>Escola Básica de Perelhal</td>\n",
       "      <td>PT_030260</td>\n",
       "      <td>PT11</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.432354e+08</td>\n",
       "      <td>POLYGON ((2787534.520 2239153.829, 2787504.074...</td>\n",
       "      <td>school</td>\n",
       "      <td>None</td>\n",
       "      <td>Escola Básica de Pousa</td>\n",
       "      <td>PT_030261</td>\n",
       "      <td>PT11</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.346576e+08</td>\n",
       "      <td>POLYGON ((2778944.922 2234377.318, 2778945.922...</td>\n",
       "      <td>school</td>\n",
       "      <td>None</td>\n",
       "      <td>Escola Básica do 1º Ciclo de Remelhe</td>\n",
       "      <td>PT_030263</td>\n",
       "      <td>PT11</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.267597e+09</td>\n",
       "      <td>POLYGON ((2783330.562 2244817.087, 2783331.724...</td>\n",
       "      <td>school</td>\n",
       "      <td>None</td>\n",
       "      <td>Escola Básica de Bárrio</td>\n",
       "      <td>PT_030264</td>\n",
       "      <td>PT11</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.267597e+09</td>\n",
       "      <td>POLYGON ((2780415.719 2238453.277, 2780424.969...</td>\n",
       "      <td>school</td>\n",
       "      <td>None</td>\n",
       "      <td>Escola Básica de Santa Eugénia</td>\n",
       "      <td>PT_030265</td>\n",
       "      <td>PT11</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         osm_id                                           geometry  \\\n",
       "0  1.851998e+08  POLYGON ((2772783.864 2240602.702, 2772815.477...   \n",
       "1  9.432354e+08  POLYGON ((2787534.520 2239153.829, 2787504.074...   \n",
       "2  1.346576e+08  POLYGON ((2778944.922 2234377.318, 2778945.922...   \n",
       "3  1.267597e+09  POLYGON ((2783330.562 2244817.087, 2783331.724...   \n",
       "4  1.267597e+09  POLYGON ((2780415.719 2238453.277, 2780424.969...   \n",
       "\n",
       "  object_type building                                  name        LAU NUTS2  \\\n",
       "0      school     None             Escola Básica de Perelhal  PT_030260  PT11   \n",
       "1      school     None                Escola Básica de Pousa  PT_030261  PT11   \n",
       "2      school     None  Escola Básica do 1º Ciclo de Remelhe  PT_030263  PT11   \n",
       "3      school     None               Escola Básica de Bárrio  PT_030264  PT11   \n",
       "4      school     None        Escola Básica de Santa Eugénia  PT_030265  PT11   \n",
       "\n",
       "  CNTR_CODE  \n",
       "0        PT  \n",
       "1        PT  \n",
       "2        PT  \n",
       "3        PT  \n",
       "4        PT  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_assets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6d1b5f9-cde0-4abc-9f32-a413df327c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base output directory \n",
    "base_out = Path(\"Exposure_files\")   \n",
    "\n",
    "# Create folder named after the asset type\n",
    "asset_folder = base_out / asset_type\n",
    "asset_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save\n",
    "country_assets.to_parquet(asset_folder / f\"{asset_type}_{country}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
